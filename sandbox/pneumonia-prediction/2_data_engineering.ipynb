{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69d61a4",
   "metadata": {},
   "source": [
    "# Notebook #2: Data Engineering\n",
    "### Transforming data across multiple nodes\n",
    "In this notebook, we'll convert chest X-rays from the DICOM format (a standard format for medical images in clinical information systems) to JPEG files. This is a critical step in most machine learning pipelines that include image classification, segmentation, or other computer vision tasks. Because in this example the data is distributed over multiple health systems and *will remain on the edge*, we'll have to send any code that converts DICOM to JPEG to each health system's server. .\n",
    "\n",
    "#### Import the Rhino Health Python library\n",
    "We'll again import any necessary functions from the `rhino_health` library and authenticate to the Rhino Cloud. Please refer to Notebook #1 for an explanation of the `session` interface for interacting with various endpoints in the Rhino Health ecosystem. In addition, you can always find more information about the Rhino SDK on our <a target=\"_blank\" href=\"https://rhinohealth.github.io/rhino_sdk_docs/html/autoapi/index.html\">Official SDK Documentation</a> and on our <a target=\"_blank\" href=\"https://pypi.org/project/rhino-health/\">PyPI Repository Page</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import rhino_health as rh\n",
    "from rhino_health.lib.endpoints.code.code_object_dataclass import (\n",
    "    CodeObject,\n",
    "    CodeObjectCreateInput,\n",
    "    CodeObjectRunInput,\n",
    "    CodeTypes,\n",
    "    CodeRunType\n",
    ")\n",
    "\n",
    "my_username = \"FCP_LOGIN_EMAIL\" # Replace this with the email you use to log into Rhino Health\n",
    "session = rh.login(username=my_username, password=getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22aa633",
   "metadata": {},
   "source": [
    "#### Retrieve Project and Relevant Datasets\n",
    "In the previous notebook we interfaced with the `Project` dataclass by first retrieving the project's unique identifier from the Rhino web platform (via copy & paste). In contrast, in this notebook we'll accomplish this by using the `get_project_by_name()` function (but either way is fine!). \n",
    "\n",
    "Each instance of the `Project` class is associated with several helpful parameters, including `description` and `permissions` that can be accessed easily through the SDK. In this example, we'll use the `collaborating_workgroups` property to retreive and encode our workgroups, which we'll use later when we perform the DICOM to JPEG transformation on 'the edge'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cffc9f-2a49-464a-8380-02a6548df34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = session.project.get_project_by_name(\"YOUR_PROJECT_NAME\")  # Replace with your project name\n",
    "\n",
    "collaborators = project.collaborating_workgroups\n",
    "workgroups_by_name = {x.name: x for x in collaborators}\n",
    "workgroups_by_uid = {x.uid: x for x in collaborators}\n",
    "hco_workgroup = workgroups_by_name[\"YOUR_HEALTH_SYSTEM_WORKGROUP\"]\n",
    "aidev_workgroup = workgroups_by_name[\"YOUR_AI_DEVELOPMENT_WORKGROUP\"]\n",
    "\n",
    "print(f\"Found workgroups '{aidev_workgroup.name}' and collaborators '{hco_workgroup.name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b52e4-ca0c-4542-859e-3d1f3159b2bc",
   "metadata": {},
   "source": [
    "#### Retrieve chest X-ray data from both participating sites\n",
    "Now that we've identified both of the collaborating workgroups involved in our project, we can retrieve the identifiers for the datasets that each workgroup uploaded to their respective Rhino clients. In a later step, we'll use the dataset identifiers to execute the DICOM to JPEG transformation code on each respective dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf0ee9-cc66-48a9-a6c3-d38d461cede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = project.datasets\n",
    "datasets_by_workgroup = {workgroups_by_uid[x.workgroup_uid].name: x for x in datasets}\n",
    "hco_cxr_dataset = project.get_dataset_by_name(\"mimic_cxr_hco\")\n",
    "aidev_cxr_dataset = project.get_dataset_by_name(\"mimic_cxr_dev\")\n",
    "hco_cxr_dataset_uid = hco_cxr_dataset.uid\n",
    "aidev_cxr_dataset_uid = aidev_cxr_dataset.uid\n",
    "print(f\"Loaded CXR datasets '{hco_cxr_dataset.uid}', '{aidev_cxr_dataset.uid}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b431d5-e830-4ac4-8c4b-201499e11d88",
   "metadata": {},
   "source": [
    "#### Create a Code Object to transform x-rays from DICOM to JPEG\n",
    "In this step, we'll use a container to convert the DICOM files to JPEG images. This functionality, referred to in the Rhino-verse as **Generalized Compute (GC)**, represents a versatile and powerful way to execute pre-built container images within the FCP environment. This Code Object type enables you to run custom code, computations, or processes that are encapsulated within container images. With GC Code Objects, you can harness the full potential of distributed computing while tailoring your computations to suit your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a37efb-4f5f-4043-8b2d-ab976e6bc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for the docker image that will convert the DICOM to JPEG\n",
    "cxr_image_uri= \"YOUR DOCKER IMAGE URL\"\n",
    "\n",
    "# retrieve schema for chest x-rays\n",
    "cxr_schema = project.get_data_schema_by_name('mimic_cxr_dev schema', project_uid=project.uid)\n",
    "cxr_schema_uid = cxr_schema.uid\n",
    "\n",
    "# define a code object by passing the path to the container image\n",
    "compute_params = CodeObjectCreateInput(\n",
    "    name=\"DICOM to JPG Transformation Code\",\n",
    "    description=\"CXR JPG transformation the AI dev and Health System datasets\",\n",
    "    input_data_schema_uids = [cxr_schema_uid],\n",
    "    output_data_schema_uids = [None], # a schema will be automatically generated\n",
    "    project_uid = project.uid,\n",
    "    code_type = CodeTypes.GENERALIZED_COMPUTE,    \n",
    "    config={\"container_image_uri\": cxr_image_uri}\n",
    ")\n",
    "\n",
    "my_code_object = session.code_object.create_code_object(compute_params)\n",
    "print(f\"Got Code Object '{my_code_object.name}' with uid {my_code_object.uid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f36033-e597-4c9b-916b-89235af73ebd",
   "metadata": {},
   "source": [
    "#### Run the Code Object\n",
    "In this step, we'll execute the code object that we just defined. We'll pass the dataset identifiers for both the AI developer's data as well as the health system's data. 'Under the hood', the container image is transmitted to both sites and executed on the respective DICOM files. As defined in the Python code within the container, the newly generated JPEG files will be saved as another dataset (with the `_conv` suffix as defined in the function argument below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626dd0a-228b-4c62-adff-12852c7a9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = CodeObjectRunInput(\n",
    "  code_object_uid = my_code_object.uid,\n",
    "  input_dataset_uids = [aidev_cxr_dataset_uid,hco_cxr_dataset_uid],     \n",
    "  output_dataset_names_suffix = \"_conv\",\n",
    "  timeout_seconds = 600\n",
    ")\n",
    "code_run = session.code_object.run_code_object(run_params)\n",
    "run_result = code_run.wait_for_completion()\n",
    "print(f\"Finished running {my_code_object.name}\")\n",
    "print(f\"Result status is '{run_result.status.value}', errors={run_result.result_info.get('errors') if run_result.result_info else None}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
