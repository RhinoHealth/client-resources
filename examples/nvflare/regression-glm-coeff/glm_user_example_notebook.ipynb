{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4793120",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c14d5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import rhino_health as rh\n",
    "from rhino_health.lib.endpoints.aimodel.aimodel_dataclass import (\n",
    "    AIModel,\n",
    "    AIModelCreateInput,\n",
    "    ModelTypes,\n",
    "    AIModelTrainInput\n",
    ")\n",
    "from rhino_health.lib.endpoints.endpoint import NameFilterMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c94de",
   "metadata": {},
   "source": [
    "#### Loging to the RHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe686128",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project_name = \"my_project\"  # Replace this with your project name on Rhino Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8304c9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_username = \"my_email@example.com\" # Replace this with the email you use to log into Rhino Health\n",
    "\n",
    "print(\"Logging In\")\n",
    "session = rh.login(username=my_username, password=getpass())\n",
    "print(\"Logged In\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc5fd9",
   "metadata": {},
   "source": [
    "#### Load project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1100670",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = session.project.get_project_by_name(my_project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b97d38",
   "metadata": {},
   "source": [
    "#### get cohorts and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c968e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = project.search_for_cohorts_by_name(cohort_base_name,name_filter_mode=NameFilterMode.CONTAINS)\n",
    "schema = cohorts[0].data_schema\n",
    "\n",
    "# Note: There are multiple ways to retrive cohorts using the SDK, this examples relies on the cohort having similar name, such as \"Site 1\" and \"Site 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95651f",
   "metadata": {},
   "source": [
    "#### Set image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac20344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_base_ecr_uri = \"my_base_ecr_uri\"  # Replace this with your workgroup ecr uri\n",
    "image_name = \"image name\"  # Replace the name of the docker image uploaded to your ecr, containing the GLM regression using nvflare code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88e990",
   "metadata": {},
   "source": [
    "#### Set config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98520eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Yb ~ Xb + COV1 + COV2 + COV3 + COV4\"\n",
    "method = \"NR\"\n",
    "glm_type = \"Binomial\"\n",
    "config_fed_server_path = \"examples/nvflare/regression-glm-coeff/config/config_fed_server.json\"  # Replace this with the path to your config server file\n",
    "config_fed_client_path = \"examples/nvflare/regression-glm-coeff/config/config_fed_client.json\"  # Replace this with the path to your config client file\n",
    "\n",
    "with open(config_fed_server_path) as f:\n",
    "    config_fed_server_input = json.loads(f.read())\n",
    "with open(config_fed_client_path) as f:\n",
    "    config_fed_client_input = json.loads(f.read())\n",
    "\n",
    "# Define the formula to use for the regression\n",
    "config_fed_client_input['executors'][0]['executor']['args']['formula'] = formula\n",
    "config_fed_client_input['executors'][0]['executor']['args']['method'] = method\n",
    "config_fed_client_input['executors'][0]['executor']['args']['glm_type'] = glm_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689db4ac",
   "metadata": {},
   "source": [
    "#### Create AI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66badbba",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "aimodel = AIModelCreateInput(\n",
    "    name=f'GLM Model Name', \n",
    "    description=\"GLM\",\n",
    "    input_data_schema_uids=[schema.uid],\n",
    "    output_data_schema_uids=[None],\n",
    "    project_uid= project.uid, \n",
    "    model_type=\"NVIDIA FLARE v2.3\", \n",
    "    config={\"container_image_uri\": f\"{my_base_ecr_uri}:{image_name}\"} \n",
    ")\n",
    "\n",
    "aimodel = session.aimodel.create_aimodel(aimodel)\n",
    "print(f\"Got aimodel '{aimodel.name}' with uid {aimodel.uid}\")\n",
    "\n",
    "run_params = AIModelTrainInput(\n",
    "aimodel_uid=aimodel.uid, \n",
    "input_cohort_uids=[cohort.uid for cohort in cohorts],\n",
    "one_fl_client_per_cohort=False ,\n",
    "validation_cohort_uids=[], \n",
    "validation_cohorts_inference_suffix=\"\",\n",
    "timeout_seconds=600,\n",
    "config_fed_server=json.dumps(config_fed_server_input), \n",
    "config_fed_client=json.dumps(config_fed_client_input), \n",
    "secrets_fed_client=\"\",\n",
    "secrets_fed_server=\"\", \n",
    "sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a4d07",
   "metadata": {},
   "source": [
    "#### Run federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting to run federated training of {aimodel.name}\")\n",
    "model_train = session.aimodel.train_aimodel(run_params)\n",
    "model_result_uid = model_train.model_result_uid\n",
    "run_result = model_train.wait_for_completion()\n",
    "print(f\"Result status is '{run_result.status.value}', errors={run_result.result_info.get('errors') if run_result.result_info else None}\")\n",
    "model_output = np.load(session.model_result.get_model_params(model_result_uid), allow_pickle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1393d32",
   "metadata": {},
   "source": [
    "#### Present results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa05f5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scalar_value = model_output.item()\n",
    "betas = scalar_value['beta'] \n",
    "stderrs = scalar_value['fed_stderror']\n",
    "print(\"Beta      (Stderr)\\n\" + \"\\n\".join([f\"{beta} ({stderr})\" for beta, stderr in (zip(betas, stderrs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31fa19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
