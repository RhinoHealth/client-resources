{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ba6e95",
   "metadata": {},
   "source": [
    "# Fitting Federated Generalized Linear Model (GLM) coefficients with FCP\n",
    "Demonstrate usage of the Rhino Health Python SDK for running GLM via NVFlare and extracting the coefficients\n",
    "\n",
    "#### Prerequisites \n",
    "1. Have two cohorts imported in FCP with variables on which you want to run the regression (e.g. 'Y', 'X', 'COV1', 'COV2', 'COV3', and 'COV4' in this example)\n",
    "2. Build a container from the NVFlare-based GLM code from this example and push it to your ECR repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4793120",
   "metadata": {},
   "source": [
    "### Initialization and Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c14d5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import rhino_health as rh\n",
    "from rhino_health.lib.endpoints.aimodel.aimodel_dataclass import (\n",
    "    AIModel,\n",
    "    AIModelCreateInput,\n",
    "    ModelTypes,\n",
    "    AIModelTrainInput\n",
    ")\n",
    "from rhino_health.lib.endpoints.endpoint import NameFilterMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8304c9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_username = \"my_email@example.com\" # Replace this with the email you use to log into Rhino Health\n",
    "\n",
    "print(\"Logging In\")\n",
    "session = rh.login(username=my_username, password=getpass.getpass())\n",
    "print(\"Logged In\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc5fd9",
   "metadata": {},
   "source": [
    "### Load the project, cohorts, and data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1100670",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project_name = \"my_project\"  # Replace this with your project name on Rhino Health\n",
    "project = session.project.get_project_by_name(my_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c968e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_search_string = \"MyCohort\"  # Replace this with a string that exists in all of the relevant cohorts' names\n",
    "cohorts = project.search_for_cohorts_by_name(cohort_search_string, name_filter_mode=NameFilterMode.CONTAINS)\n",
    "schema = cohorts[0].data_schema\n",
    "\n",
    "# Note: There are multiple ways to retrive cohorts using the SDK, this examples relies on the cohort having similar name, such as \"MyCohort 1\" and \"MyCohort 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95651f",
   "metadata": {},
   "source": [
    "### Create the model object with the desired configuration (including regression formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac20344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_base_ecr_uri = \"my_base_ecr_uri\"  # Replace this with your workgroup ecr uri\n",
    "image_name = \"image name\"  # Replace the name of the docker image uploaded to your ecr, containing the GLM regression using nvflare code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88e990",
   "metadata": {},
   "source": [
    "#### Define the config (regression formula, regression family, optimization method, etc.) in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98520eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Yb ~ Xb + COV1 + COV2 + COV3 + COV4\"\n",
    "method = \"IRLS\"  # Meaning we'll be using IRLS for optimization and not Newton Raphson\n",
    "glm_type = \"Binomial\"  # Meaning we'll be using a logistic regression\n",
    "config_fed_client_path = \"examples/nvflare/regression-glm-coeff/config/config_fed_client.json\"  # Replace this with the path to your config client file\n",
    "\n",
    "with open(config_fed_client_path) as f:\n",
    "    config_fed_client_input = json.loads(f.read())\n",
    "\n",
    "# Define the formula to use for the regression\n",
    "config_fed_client_input['executors'][0]['executor']['args']['formula'] = formula\n",
    "config_fed_client_input['executors'][0]['executor']['args']['method'] = method\n",
    "config_fed_client_input['executors'][0]['executor']['args']['glm_type'] = glm_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689db4ac",
   "metadata": {},
   "source": [
    "#### Create the AI Model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66badbba",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "aimodel = AIModelCreateInput(\n",
    "    name=f'GLM Model Name', \n",
    "    description=\"GLM\",\n",
    "    input_data_schema_uids=[schema.uid],\n",
    "    output_data_schema_uids=[None],\n",
    "    project_uid= project.uid, \n",
    "    model_type=\"NVIDIA FLARE v2.3\", \n",
    "    config={\"container_image_uri\": f\"{my_base_ecr_uri}:{image_name}\"} \n",
    ")\n",
    "\n",
    "aimodel = session.aimodel.create_aimodel(aimodel)\n",
    "print(f\"Got aimodel '{aimodel.name}' with uid {aimodel.uid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a4d07",
   "metadata": {},
   "source": [
    "### Run the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = AIModelTrainInput(\n",
    "    aimodel_uid=aimodel.uid, \n",
    "    input_cohort_uids=[cohort.uid for cohort in cohorts],\n",
    "    one_fl_client_per_cohort=False ,\n",
    "    validation_cohort_uids=[], \n",
    "    validation_cohorts_inference_suffix=\"\",\n",
    "    timeout_seconds=600,\n",
    "    config_fed_server=json.dumps(config_fed_server_input), \n",
    "    config_fed_client=json.dumps(config_fed_client_input), \n",
    "    secrets_fed_client=\"\",\n",
    "    secrets_fed_server=\"\", \n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(f\"Starting to run federated training of {aimodel.name}\")\n",
    "model_train = session.aimodel.train_aimodel(run_params)\n",
    "model_result_uid = model_train.model_result_uid\n",
    "run_result = model_train.wait_for_completion()\n",
    "print(f\"Result status is '{run_result.status.value}', errors={run_result.result_info.get('errors') if run_result.result_info else None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1393d32",
   "metadata": {},
   "source": [
    "### Load and display the resulting coefficients and stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa05f5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_output = np.load(session.model_result.get_model_params(model_result_uid), allow_pickle=True)\n",
    "\n",
    "scalar_value = model_output.item()\n",
    "betas = scalar_value['beta'] \n",
    "stderrs = scalar_value['fed_stderror']\n",
    "print(\"Beta      (Stderr)\\n\" + \"\\n\".join([f\"{beta} ({stderr})\" for beta, stderr in (zip(betas, stderrs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ecf34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
