{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5932078e",
   "metadata": {},
   "source": [
    "# Run time external files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72703e",
   "metadata": {},
   "source": [
    "In this notebook we will explain how to use files from a workgroup s3 bucket in your code run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f0f5a",
   "metadata": {},
   "source": [
    "For your code to be able to access files while running in your agent we need do 4 steps:\n",
    "  1. Create a S3 bucket for the workgroup files.\n",
    "  2. Upload the relevant files to the bucket\n",
    "  3. Reference the files in your code.\n",
    "  4. Tell the code run what files to download from the bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aebfbb",
   "metadata": {},
   "source": [
    "### 1. Creating the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85dc677",
   "metadata": {},
   "source": [
    "The bucket is created as part of the onborading process into the FCP by client request, if you want to create a bucket please contact support@rhinohealth.com for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6972dd0",
   "metadata": {},
   "source": [
    "### 2. Uploading files to the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c023cb5",
   "metadata": {},
   "source": [
    "AWS offers many alternative ways to [upload files to an S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/upload-objects.html), we also provided a [script](https://github.com/RhinoHealth/user-resources/blob/main/rhino-utils/upload-file-to-s3.sh) in our user_resource repository you can use.  \n",
    "  You need to define your S3 credentials and then you can call the script like this:\n",
    "  \n",
    "  `./upload-file-to-s3.sh ./the_folder_to_upload name_of_the_bucket the_folder_in_s3_you_want_to_upload_to`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156310f5",
   "metadata": {},
   "source": [
    "### 3. Refence the files in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c2d87",
   "metadata": {},
   "source": [
    "In the run all the files will be uploaded to the container to the **/external_data** folder with the same folder structure as in the S3 bucket.\n",
    "So if the file in the bucket is `/test_1_folder/model_params.txt`,\n",
    "in the container run they would be avalble under `/external_data/test_1_folder/model_params.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09412ac",
   "metadata": {},
   "source": [
    "### 4. Use the files in the specific run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhino_health.lib.endpoints.code_object.code_object_dataclass import (\n",
    "    CodeObjectCreateInput,\n",
    "    CodeObjectRunInput,\n",
    "    CodeTypes,\n",
    ")\n",
    "from textwrap import dedent\n",
    "\n",
    "# In this example we use CodeTypes.PYTHON_CODE to show how the access looks in the code, \n",
    "# but you can use all CodeTypes.\n",
    "new_code_object = CodeObjectCreateInput(\n",
    "    name=\"Example code object\",\n",
    "    description=\"A code that references a file\",\n",
    "    code_type=CodeTypes.PYTHON_CODE,\n",
    "    version=0,\n",
    "    project_uid=project.uid,\n",
    "    config={\n",
    "        \"python_version\": \"3.9\",\n",
    "        \"requirements\": [\"numpy == 1.22.*\", \"pandas ~= 1.4.2\"],\n",
    "        \"python_code\": dedent(\n",
    "            \"\"\"\n",
    "            from pathlib import Path\n",
    "            text = Path('/external_data/data_files/example_file1.txt').read_text()\n",
    "            \"\"\"\n",
    "            ),\n",
    "        \"code_execution_mode\": \"snippet\",\n",
    "    },\n",
    "    input_data_schema_uids=[None],\n",
    "    output_data_schema_uids=[None],\n",
    ")\n",
    "code_object = session.code_object.create_code_object(new_code_object)\n",
    "run_params = CodeObjectRunInput(\n",
    "    code_object_uid=code_object.uid,\n",
    "    input_dataset_uids=[[dataset.uid]],\n",
    "    output_dataset_names_suffix=\"test\",\n",
    "    # this is the new variable where your reference the bucket files you want to access in the run.\n",
    "    external_storage_file_paths=[\n",
    "        \"data_files/example_file1.txt\",\n",
    "        \"data_files/example_file2.txt\",\n",
    "    ], \n",
    "    timeout_seconds=600,\n",
    "    sync=True,\n",
    ")\n",
    "run_result = session.code_object.run_code_object(run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c0245-8953-4ca8-9a4e-5544a79a5b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
